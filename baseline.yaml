train_dataset:
  target: src.mvhuman.MergedSubjectDataset
  params:
    split_file: 'wentai_share/mvhuman/train-front_back-A_pose.txt' # wentai_share/mvhuman/train-4_camera-8_frame-bad_mask_filtered-no_obj_filtered.txt
    data_prefix: 'dataset/mvhuman/mvhuman_subset_v4_final'
    anno_prefix: 'wentai_share/mvhuman'
    semantic_num: 10 # (4 head&shoes, 6 cloth)
    is_debug: false

val_dataset:
  target: src.mvhuman.MergedSubjectDataset
  params:
    split_file: wentai_share/mvhuman/test-front_back-A_pose.txt # wentai_share/mvhuman/test-4_camera-2_frame_less.txt
    data_prefix: 'dataset/mvhuman/mvhuman_subset_v4_final'
    anno_prefix: 'wentai_share/mvhuman'
    semantic_num: 10 # (4 head&shoes, 6 cloth)
    is_debug: false
    load_img: false

img_path: nature_0001.jpg

scheduler:
  weighting_scheme: logit_normal # choices=['sigma_sqrt', 'logit_normal', 'mode', 'cosmap']
  logit_mean: 0.0
  logit_std: 1.0
  mode_scale: 1.29

optimizer:
  optimizer: adamw
  gen_learning_rate: 2e-4
  disc_learning_rate: 2e-4
  adam_beta1: 0.9
  adam_beta2: 0.999
  adam_weight_decay: 1e-04
  adam_epsilon: 1e-08
  lr_scheduler: constant # choices=['linear', 'cosine', 'constant', 'constant_with_warmup']
  lr_warmup_steps: 0
  lr_num_cycles: 1
  lr_power: 1.0
  use_8bit_adam: false

train:
  output_dir: 'experiments/mvton-baseline_controlnet'
  resume_from_checkpoint: null
  lambda_A: 1.0
  lambda_B: 10.0
  train_batch_size: 16
  num_validation_images: 4
  dataloader_num_workers: 4
  mixed_precision: bf16
  gradient_accumulation_steps: 1
  gradient_checkpointing: true
  num_train_epochs: 20
  max_grad_nrom: 1.0
  max_train_steps: 50000
  validation_steps: 2500 # 5000
  checkpointing_steps: 5000 # 10000
  checkpoints_total_limit: 3
  cfg_prob: 0.1 # probability for classifier-free guidance
  seed: 0
